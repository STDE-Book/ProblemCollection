\ifspanish

\question[25] % VGV

Se desea estimar el valor de la v.a. $S$ a partir de la observación de otra variable aleatoria $X$, de las que se conoce su distribución conjunta
$$p_{S,X}(s,x) = 4x,  \qquad 0 \le s \le x^2, ~~ 0 \le x \le 1$$
Obtenga:
\begin{parts}
\part El estimador de máxima verosimilitud de $S$ a la vista de $X$, $\SML$.
\part El estimador de máximo a posteriori de $S$ a la vista de $X$, $\SMAP$. 
\part El estimador de mínimo error cuadrático medio de $S$ a la vista de $X$, $\SMSE$.
\part El estimador lineal de  mínimo error cuadrático medio de $S$ a la vista de $X$, $\SLMSE = w_0+w_1x$.
\end{parts}

\begin{solution}
\begin{parts}
\part 
The prior distribution is
\begin{align*}
p_S(s) &= \int_{-\infty}^{\infty} p_{S,X}(s,x) dx
	    = \int_{\sqrt{s}}^{1} 4x dx = 2(1 - s)   
\end{align*}
Therefore, the likelihood function is
\begin{align*}
p_{X|S}(x|s) &= \frac{p_{X,S}(x,s)}{p_S(s)} 
	          = \frac{x}{1-s}            \qquad 0 \le s \le x^2, \qquad 0 \le x \le 1
\end{align*}
which is an increasing function of $s$. Thus, the ML estimate is the maximum value of $s$ in the domain of the likelihood function, that is
$$\SML = X^2$$

\part 
\begin{align*}
\sMAP = \argmax_s p_{S|X}(s|x) 
	  = \argmax_s p_{S,X}(s, x) 
	  = \argmax_s 4x 
\end{align*}
Thus, $\SMAP$ is not unique: any value of $s \in [0,X^2]$ is a MAP estimate.
\part
Since the marginal distribution is
\begin{align*}
p_X(x) &= \int_{-\infty}^{\infty} p_{S,X}(s,x) ds
	    = \int_0^{x^2} 4x ds = 4x^3
\end{align*}
the posterior distribution is
\begin{align*}
p_{S|X}(s|x) &= \frac{p_{X,S}(x,s)}{p_X(x)} 
	          = \frac{1}{x^2}            \qquad 0 \le s \le x^2 \le 1
\end{align*}
Therefore
\begin{align*}
\sMSE
	&= \EE\{S|x\} 
	 = \int_{-\infty}^{\infty} s p_{S|X}(s|x) ds
	 = \int_0^{x^2} \frac{s}{x^2} ds = \frac{x^2}{2} 	 
\end{align*}
\part Since $\SLMSE = {\bf w}^\intercal {\bf Z}$, where ${\bf Z} = (1, X)^\intercal$, we have
\begin{align*}
{\bf w} 
    &= {\bf R}_{\bf Z}^{-1}{\bf r}_{S{\bf Z}}  \\
{\bf R}_{\bf Z}
    &= \EE\{{\bf Z}{\bf Z}^\intercal\} 
     = \begin{pmatrix} 
       1        & \EE\{X\}   \\
       \EE\{X\} & \EE\{X^2\} 
       \end{pmatrix}  \\
{\bf r}_{S{\bf Z}}
    &= \EE\{S{\bf Z}\} 
     = \begin{pmatrix} \EE\{S\} \\ \EE\{SX\} \end{pmatrix}
\end{align*}
Noting that
\begin{align*}
\EE\{X\}   &= \int_0^1 4x^4 dx = \frac45   \\
\EE\{X^2\} &= \int_0^1 4x^5 dx = \frac23   \\
\EE\{S\}   &= \int_0^1 2s(1-s) ds = \frac13   \\
\EE\{SX\}
	&= \int_0^1 \EE\{Sx|x\}p_X(x) dx 
     = \int_0^1 \frac{x^3}{2} 4x^3 dx = \frac27
\end{align*}
we get
\begin{align*}
{\bf w} 
    &= \begin{pmatrix} 
       1       & \frac45  \\
       \frac45 & \frac23 
       \end{pmatrix}^{-1} 
       \begin{pmatrix} 
       \frac13   \\  \frac27 
       \end{pmatrix}
     = \begin{pmatrix} 
       -\frac5{21} \\ \frac57 
       \end{pmatrix}
\end{align*}
Thus
$\SLMSE =  \frac57 X - \frac5{21} $
\end{parts}
\end{solution}

\else

\question[25] % VGV

We want to estimate the value of a random variable $S$ using a random observation $X$, from which the joint probability distribution is known
$$p_{S,X}(s,x) = 4x,  \qquad 0 \le s \le x^2, \qquad 0 \le x \le 1$$
Obtain:
\begin{parts}
\part The maximum likelihood estimator of $S$ given $X$, $\SML$.
\part The maximum {\em a posteriori} estimator of $S$ given $X$, $\SMAP$.
\part The minimum mean square error estimator of $S$ given $X$, $\SMSE$. 
\part The linear estimator of $S$, with minimum mean square error, given $X$, $\SLMSE=w_0+w_1x$.
\end{parts}

\begin{solution}
\begin{parts}
\part 
The prior distribution is
\begin{align*}
p_S(s) &= \int_{-\infty}^{\infty} p_{S,X}(s,x) dx
	    = \int_{\sqrt{s}}^{1} 4x dx = 2(1 - s)   
\end{align*}
Therefore, the likelihood function is
\begin{align*}
p_{X|S}(x|s) &= \frac{p_{X,S}(x,s)}{p_{S}(s)} 
	          = \frac{x}{1-s}            \qquad 0 \le s \le x^2, \qquad 0 \le x \le 1
\end{align*}
which is an increasing function of $s$. Thus, the ML estimate is the maximum value of $s$ in the domain of the likelihood function, that is
$$\SML = X^2$$

\part 
\begin{align*}
\sMAP = \argmax_s p_{S|X}(s|x) 
	  = \argmax_s p_{S,X}(s, x) 
	  = \argmax_s 4x 
\end{align*}
Thus, $\SMAP$ is not unique: any value of $s \in [0,X^2]$ is a MAP estimate.
\part
Since the marginal distribution is
\begin{align*}
p_X(x) &= \int_{-\infty}^{\infty} p_{S,X}(s,x) ds
	    = \int_0^{x^2} 4x ds = 4x^3
\end{align*}
the posterior distribution is
\begin{align*}
p_{S|X}(s|x) &= \frac{p_{X,S}(x,s)}{p_X(x)} 
	          = \frac{1}{x^2}            \qquad 0 \le s \le x^2 \le 1
\end{align*}
Therefore
\begin{align*}
\sMSE
	&= \EE\{S|x\} 
	 = \int_{-\infty}^{\infty} s p_{S|X}(s|x) ds
	 = \int_0^{x^2} \frac{s}{x^2} ds = \frac{x^2}{2} 	 
\end{align*}
\part Since $\SLMSE = {\bf w}^\intercal {\bf Z}$, where ${\bf Z} = (1, X)^\intercal$, we have
\begin{align*}
{\bf w} 
    &= {\bf R}_{\bf Z}^{-1}{\bf r}_{S{\bf Z}}  \\
{\bf R}_{\bf Z}
    &= \EE\{{\bf Z}{\bf Z}^\intercal\} 
     = \begin{pmatrix} 
       1        & \EE\{X\}   \\
       \EE\{X\} & \EE\{X^2\} 
       \end{pmatrix}  \\
{\bf r}_{S{\bf Z}}
    &= \EE\{S{\bf Z}\} 
     = \begin{pmatrix} \EE\{S\} \\ \EE\{SX\} \end{pmatrix}
\end{align*}
Noting that
\begin{align*}
\EE\{X\}   &= \int_0^1 4x^4 dx = \frac45   \\
\EE\{X^2\} &= \int_0^1 4x^5 dx = \frac23   \\
\EE\{S\}   &= \int_0^1 2s(1-s) ds = \frac13   \\
\EE\{SX\}
	&= \int_0^1 \EE\{Sx|x\}p_X(x) dx 
     = \int_0^1 \frac{x^3}{2} 4x^3 dx = \frac27
\end{align*}
we get
\begin{align*}
{\bf w} 
    &= \begin{pmatrix} 
       1       & \frac45  \\
       \frac45 & \frac23 
       \end{pmatrix}^{-1} 
       \begin{pmatrix} 
       \frac13   \\  \frac27 
       \end{pmatrix}
     = \begin{pmatrix} 
       -\frac5{21} \\ \frac57 
       \end{pmatrix}
\end{align*}
Thus
$\SLMSE =  \frac57 X - \frac5{21} $
\end{parts}
\end{solution}

\fi